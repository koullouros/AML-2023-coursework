{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HYPERPARAMETERS\nThe hyperparameters are configured here, the rest of the notebook can then be run and everything will be done automatically. for SimCLR finetuning to work, SimCLR needs to be pretrained first ofcourse, otherwise there will be a file not found error. SimCLR pretraining does not work on kaggle unless a really small batch size is used, otherwise will run into CUDA out of memory error.","metadata":{}},{"cell_type":"code","source":"# parameters for simCLR pretraining\nDO_PRETRAINING = False # if false will skip pretraining simclr\nSIMCLR_BATCH_SIZE = 16 # used higher in colab but will crash on kaggle due to out of memory\nSIMCLR_EPOCHS = 10\nSIMCLR_FP = \"SIMCLR_PRETRAINED.pt\"\n\n# parameters for finetuning and other models\nBATCH_SIZE = 64\nEPOCHS = 10\nLEARNING_RATE = 2e-3\nOPTIMIZER = \"ADAM\" # ADAM / LION\nMODEL = \"Efficientnet_b0\" # Standard / Resnet50 / SimCLR / Efficientnet_b0","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:11:31.785932Z","iopub.execute_input":"2023-05-19T20:11:31.786687Z","iopub.status.idle":"2023-05-19T20:11:31.795774Z","shell.execute_reply.started":"2023-05-19T20:11:31.786655Z","shell.execute_reply":"2023-05-19T20:11:31.794719Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# ADDITIONAL LIBRARIES","metadata":{}},{"cell_type":"code","source":"!pip install simclr\n!pip install lion-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:11:34.083371Z","iopub.execute_input":"2023-05-19T20:11:34.083721Z","iopub.status.idle":"2023-05-19T20:11:59.841695Z","shell.execute_reply.started":"2023-05-19T20:11:34.083693Z","shell.execute_reply":"2023-05-19T20:11:59.840509Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting simclr\n  Downloading simclr-1.0.2-py3-none-any.whl (21 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from simclr) (2.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from simclr) (6.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from simclr) (0.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->simclr) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->simclr) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->simclr) (4.5.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->simclr) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->simclr) (3.11.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->simclr) (9.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->simclr) (2.28.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->simclr) (1.23.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->simclr) (2.1.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->simclr) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->simclr) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->simclr) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->simclr) (3.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->simclr) (1.3.0)\nInstalling collected packages: simclr\nSuccessfully installed simclr-1.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting lion-pytorch\n  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from lion-pytorch) (2.0.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion-pytorch) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion-pytorch) (1.11.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion-pytorch) (4.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion-pytorch) (3.11.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->lion-pytorch) (3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->lion-pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->lion-pytorch) (1.3.0)\nInstalling collected packages: lion-pytorch\nSuccessfully installed lion-pytorch-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# IMPORTS","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport torchvision.transforms as transforms\n\nimport os\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nfrom tqdm import tqdm\n\nfrom simclr import SimCLR\nfrom simclr.modules import get_resnet, NT_Xent\nfrom simclr.modules.transformations import TransformsSimCLR\n\nfrom lion_pytorch import Lion\n\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\nimport matplotlib.pyplot as plt\n\nfrom simclr import SimCLR\nfrom simclr.modules import get_resnet, NT_Xent\nfrom simclr.modules.transformations import TransformsSimCLR\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:11:59.844291Z","iopub.execute_input":"2023-05-19T20:11:59.845001Z","iopub.status.idle":"2023-05-19T20:11:59.887145Z","shell.execute_reply.started":"2023-05-19T20:11:59.844943Z","shell.execute_reply":"2023-05-19T20:11:59.886470Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:11:59.888428Z","iopub.execute_input":"2023-05-19T20:11:59.889133Z","iopub.status.idle":"2023-05-19T20:11:59.894822Z","shell.execute_reply.started":"2023-05-19T20:11:59.889099Z","shell.execute_reply":"2023-05-19T20:11:59.893943Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# DATASET\nTwo datasets are needed, one for SimCLR to use which returns two images, and one for the other models which returns an image and a target.","metadata":{}},{"cell_type":"code","source":"class MelanomaSimCLRDataset(Dataset):\n    def __init__(self, df, img_path, train, image_transforms):\n        self.df = df\n        self.img_path = img_path\n        self.train = train\n        self.transforms = image_transforms\n        \n    def __getitem__(self, index):\n        image_path = os.path.join(self.img_path, self.df.iloc[index]['image_name'] + '.jpg')\n        x = cv2.imread(image_path)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n        x = cv2.resize(x, (224, 224))\n        x = Image.fromarray(x)\n\n        x1, x2 = self.transforms(x)\n            \n        return x1, x2\n    \n    def __len__(self):\n        return len(self.df)\n\nclass MelanomaDataset(Dataset):\n    def __init__(self, df, img_path, train, image_transforms):\n        self.df = df\n        self.img_path = img_path\n        self.train = train\n        self.transform = image_transforms\n        \n    def __getitem__(self, index):\n        image_path = os.path.join(self.img_path, self.df.iloc[index]['image_name'] + '.jpg')\n        x = cv2.imread(image_path)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n        x = cv2.resize(x, (224, 224))\n        x = Image.fromarray(x)\n        x = self.transform(x)\n\n        if self.train:\n          y = self.df.iloc[index]['target']\n          return x, y.astype(\"float32\")\n        else:\n          return x, self.df.iloc[index]['image_name']\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:11:59.897531Z","iopub.execute_input":"2023-05-19T20:11:59.898494Z","iopub.status.idle":"2023-05-19T20:11:59.911816Z","shell.execute_reply.started":"2023-05-19T20:11:59.898461Z","shell.execute_reply":"2023-05-19T20:11:59.910808Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Here 10000 images are used for pretraining ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')\n\npositive_classes = train_df[train_df['target'] == 1]\nnegative_classes = train_df[train_df['target'] == 0][-10000:]\n\ntrain_df_simclrpretraining = negative_classes\n\nsimclr_train_dataset = MelanomaSimCLRDataset(df=train_df_simclrpretraining,\n                               img_path=\"/kaggle/input/siim-isic-melanoma-classification/jpeg/train/\",\n                               train=True,\n                               image_transforms=TransformsSimCLR((224,224)))\n\n# Dataloader for SimCLR Pretraining\nsimclr_train_loader = DataLoader(dataset=simclr_train_dataset, shuffle=True, batch_size=SIMCLR_BATCH_SIZE, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:11:59.914588Z","iopub.execute_input":"2023-05-19T20:11:59.915135Z","iopub.status.idle":"2023-05-19T20:12:00.037635Z","shell.execute_reply.started":"2023-05-19T20:11:59.915097Z","shell.execute_reply":"2023-05-19T20:12:00.036770Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"The rest of the models will use an even split of positive and negative classes. Train/Validation split is 80/20","metadata":{}},{"cell_type":"code","source":"positive_classes = train_df[train_df['target'] == 1]\nnegative_classes = train_df[train_df['target'] == 0][:len(positive_classes)]\ntrain_df = pd.concat([positive_classes, negative_classes])\n\ntest_df = pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')\n\nnum_melanoma = sum(train_df['target'] == 1)\nnum_nomelanoma = sum(train_df['target'] == 0)\nprint(f\"Number of images with melanoma: {num_melanoma}\")\nprint(f\"Number of images without melanoma: {num_nomelanoma}\")\n\nX = train_df[['image_name', 'target']]\ny = train_df['target']\n\ntrain_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=1999, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:12:00.038937Z","iopub.execute_input":"2023-05-19T20:12:00.039286Z","iopub.status.idle":"2023-05-19T20:12:00.090160Z","shell.execute_reply.started":"2023-05-19T20:12:00.039255Z","shell.execute_reply":"2023-05-19T20:12:00.089178Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Number of images with melanoma: 584\nNumber of images without melanoma: 584\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The transforms used by all models except simclr pretraining. We mainly use 224x224 and normalize. We also only use horizontal and vertical flip transforms.","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize(size=(224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(size=(224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:12:00.091631Z","iopub.execute_input":"2023-05-19T20:12:00.092271Z","iopub.status.idle":"2023-05-19T20:12:00.100096Z","shell.execute_reply.started":"2023-05-19T20:12:00.092240Z","shell.execute_reply":"2023-05-19T20:12:00.099209Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Datasets for the rest of the models are defined here","metadata":{}},{"cell_type":"code","source":"train_dataset = MelanomaDataset(df=train_df,\n                                img_path=\"/kaggle/input/siim-isic-melanoma-classification/jpeg/train/\",\n                                train=True,\n                                image_transforms = train_transform)\nval_dataset = MelanomaDataset(df=valid_df,\n                                img_path=\"/kaggle/input/siim-isic-melanoma-classification/jpeg/train/\",\n                                train=True,\n                                image_transforms = test_transform)\ntest_dataset = MelanomaDataset(df=test_df, \n                               img_path=\"/kaggle/input/siim-isic-melanoma-classification/jpeg/test/\",\n                               train=False,\n                               image_transforms = test_transform)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:12:00.101566Z","iopub.execute_input":"2023-05-19T20:12:00.101891Z","iopub.status.idle":"2023-05-19T20:12:00.110736Z","shell.execute_reply.started":"2023-05-19T20:12:00.101861Z","shell.execute_reply":"2023-05-19T20:12:00.109849Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"The loaders are defined here","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:12:00.112048Z","iopub.execute_input":"2023-05-19T20:12:00.112514Z","iopub.status.idle":"2023-05-19T20:12:00.125392Z","shell.execute_reply.started":"2023-05-19T20:12:00.112484Z","shell.execute_reply":"2023-05-19T20:12:00.124543Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# SIMCLR PRETRAINING\nThe model is defined here. Weights are used from Imagenet Pretraining with SimCLR. ","metadata":{}},{"cell_type":"code","source":"# download the pretrained weights\n!wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n    \n# loss is NT_Xent\ncriterion = NT_Xent(SIMCLR_BATCH_SIZE, 0.5, world_size=1)\n\n# get the encoder\nencoder = get_resnet(\"resnet50\", pretrained=False)\nn_features = encoder.fc.in_features  # get dimensions of fc layer\n\nmodel = SimCLR(encoder, 64, n_features)\n\nmodel_fp = \"checkpoint_100.tar\"\n# load pretrained\nmodel.load_state_dict(torch.load(model_fp, map_location=device))\nmodel = model.to(device)\n\n\n# optimizer\noptimizer = torch.optim.AdamW(model.parameters())\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:43:31.492197Z","iopub.execute_input":"2023-05-19T12:43:31.492864Z","iopub.status.idle":"2023-05-19T12:43:38.376595Z","shell.execute_reply.started":"2023-05-19T12:43:31.492829Z","shell.execute_reply":"2023-05-19T12:43:38.375441Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"--2023-05-19 12:43:32--  https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\nResolving github.com (github.com)... 192.30.255.113\nConnecting to github.com (github.com)|192.30.255.113|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230519%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230519T124332Z&X-Amz-Expires=300&X-Amz-Signature=fb2f2d1f514e15c402cc1bbb6d787705cfdfc2a5b58a0c2a326552b4fdbba4c9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream [following]\n--2023-05-19 12:43:32--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230519%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230519T124332Z&X-Amz-Expires=300&X-Amz-Signature=fb2f2d1f514e15c402cc1bbb6d787705cfdfc2a5b58a0c2a326552b4fdbba4c9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 111607632 (106M) [application/octet-stream]\nSaving to: ‘checkpoint_100.tar’\n\ncheckpoint_100.tar  100%[===================>] 106.44M  72.0MB/s    in 1.5s    \n\n2023-05-19 12:43:34 (72.0 MB/s) - ‘checkpoint_100.tar’ saved [111607632/111607632]\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Pretrain SimCLR\nTraining method adapted from https://github.com/Spijkervet/SimCLR (specifically the provided colab notebook available at https://colab.research.google.com/drive/1ObAYvVKQjMG5nd2wIno7j2y_X91E9IrX)\n","metadata":{}},{"cell_type":"code","source":"def simclr_train(train_loader, model, criterion, optimizer):\n    global_step = 0\n    loss_epoch = 0\n    with tqdm(total=len(train_loader)) as pbar:\n        for step, (x_i, x_j) in enumerate(train_loader):\n            optimizer.zero_grad()\n            x_i = x_i.cuda(non_blocking=True)\n            x_j = x_j.cuda(non_blocking=True)\n\n            # get the latent representations for the two images\n            h_i, h_j, z_i, z_j = model(x_i, x_j)\n            \n            # similarity\n            loss = criterion(z_i, z_j)\n            loss.backward()\n\n            optimizer.step()\n\n            loss_epoch += loss.item()\n            global_step += 1\n\n            pbar.update(1)\n\n    return loss_epoch / len(train_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DO_PRETRAINING:\n    for epoch in range(SIMCLR_EPOCHS):\n        loss = simclr_train(simclr_train_loader, model, criterion, optimizer)\n        torch.cuda.empty_cache()\n        print(f\"Epoch [{epoch}] - Loss: {loss}\")\n        \ntorch.save(model, SIMCLR_FP)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SIMCLR FINETUNING AND OTHER MODELS\nThis section trains the specified model from the hyperparameters. Either continues finetuning the Resnet50 from SimCLR or trains other models used in our experiments from scratch, depending on the selection in the hyperparameters.","metadata":{}},{"cell_type":"markdown","source":"## Helper Functions\nThese functions are used to train and test the models","metadata":{}},{"cell_type":"code","source":"def train(train_loader, model, criterion, optimizer, scheduler = None):\n    loss_epoch = 0\n\n    model.train()\n    with tqdm(total=len(train_loader)) as pbar:\n        for i, (inputs, labels) in enumerate(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = torch.sigmoid(model(inputs).squeeze(dim=1).float())\n            loss = criterion(outputs, labels)\n            loss_epoch += loss.item()\n\n            loss.backward()\n\n            optimizer.step()\n\n            if scheduler is not None:\n                scheduler.step()\n\n            pbar.update(1)\n    return loss / len(train_loader)\n\ndef make_preds(val_loader, model):\n    model.eval()\n    true_labels = []\n    predicted_labels = []\n    with tqdm(total=len(val_loader)) as pbar:\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = torch.sigmoid(model(inputs))\n                preds = outputs.float()\n\n                true_labels.extend(labels.detach().cpu().numpy())\n                predicted_labels.extend(preds.detach().cpu().numpy())\n\n                pbar.update(1)\n    return predicted_labels, true_labels\n  \ndef make_preds_test(test_loader, model):\n    model.eval()\n    filenames = []\n    predicted_labels = []\n\n    with tqdm(total=len(test_loader)) as pbar:\n        with torch.no_grad():\n            for inputs, fns in test_loader:\n                inputs = inputs.to(device)\n\n                outputs = torch.sigmoid(model(inputs))\n                preds = outputs.float()\n\n                filenames.extend(fns)\n                predicted_labels.extend(preds.detach().cpu().numpy())\n\n                pbar.update(1)\n\n    return predicted_labels,filenames\n\n\n\ndef train_model(train_loader, model, epochs, criterion, optimizer, scheduler = None):\n    prev_best_f1 = 0\n    for epoch in range(epochs):\n        loss = train(train_loader, model, criterion, optimizer, scheduler)\n        print(f\"Epoch {epoch+1}, Loss: {loss}\")\n\n        predicted_labels, true_labels = make_preds(val_loader, model)\n        accuracy = accuracy_score(true_labels, np.array(predicted_labels) > 0.5)\n        f1 = f1_score(true_labels, np.array(predicted_labels) > 0.5)\n        precision = precision_score(true_labels, np.array(predicted_labels) > 0.5)\n        recall = recall_score(true_labels, np.array(predicted_labels) > 0.5)\n\n        if f1 > prev_best_f1:\n            prev_best_f1 = f1\n            torch.save(model, 'best_model.pt')\n\n        print(f'Accuracy: {accuracy} \\t F1 Score: {f1} \\t Precision: {precision} \\t Recall: {recall}')\n\n        model = torch.load('best_model.pt', map_location=device)\n    print('Finished Training')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:12:00.130245Z","iopub.execute_input":"2023-05-19T20:12:00.130524Z","iopub.status.idle":"2023-05-19T20:12:00.147317Z","shell.execute_reply.started":"2023-05-19T20:12:00.130489Z","shell.execute_reply":"2023-05-19T20:12:00.146084Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Model Definitions\nAll models are defined here in a way that is automated. The correct model will be defined depending on the configuration set.\nThe two models taken from other coursemates are the baseline cnn model and efficientnet. They were included here for evaluation and visualization.","metadata":{}},{"cell_type":"code","source":"def get_baseline_model():\n    # this is taken from Ankitta Bhatt's part. It is included here for evaluation and visualization\n    model = nn.Sequential(\n        # Convolutional layers\n        nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n        nn.BatchNorm2d(16),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n        nn.BatchNorm2d(32),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n        nn.BatchNorm2d(64),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n        nn.BatchNorm2d(128),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n\n        # Flatten layer\n        nn.Flatten(),\n\n        # Fully connected layers\n        nn.Linear(25088, 512),\n        nn.BatchNorm1d(512),\n        nn.ReLU(),\n        nn.Linear(512, 256),\n        nn.BatchNorm1d(256),\n        nn.ReLU(),\n        nn.Linear(256, 1),\n      )\n    return model\n\ndef get_simclr_model(fp):\n    model = torch.load(fp, map_location=device)\n    model = model.encoder\n    model.fc = nn.Linear(2048, 1)\n    model.fc.requires_grad = True\n    return model\n\ndef get_resnet_model():\n    model = torchvision.models.resnet50(pretrained=True)\n    model.fc = nn.Linear(model.fc.in_features, 1)\n    return model\n\ndef get_efficientnet_model():\n    # this is taken from Prageeth Krishnan's part. It is included here for evaluation and visualization\n    model = torchvision.models.efficientnet_b0(pretrained=True)\n    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n    return model\n\ndef get_model(model_name, simclr_fp=None):\n    if model_name == \"Standard\":\n        model = get_baseline_model()\n    elif model_name == \"SimCLR\":\n        model = get_simclr_model(simclr_fp)\n    elif model_name == \"Resnet50\":\n        model = get_resnet_model()\n    elif model_name == \"Efficientnet_b0\":\n        model = get_efficientnet_model()\n        \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:13:45.245477Z","iopub.execute_input":"2023-05-19T20:13:45.245827Z","iopub.status.idle":"2023-05-19T20:13:45.259763Z","shell.execute_reply.started":"2023-05-19T20:13:45.245798Z","shell.execute_reply":"2023-05-19T20:13:45.258859Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer and Criterion","metadata":{}},{"cell_type":"code","source":"model = get_model(MODEL, SIMCLR_FP)\nmodel = model.to(device)\n\ncriterion = nn.BCELoss()\nif OPTIMIZER == \"LION\":\n    optimizer = Lion(model.parameters(), lr=LEARNING_RATE)\nelif OPTIMIZER == \"ADAM\":\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:13:46.962520Z","iopub.execute_input":"2023-05-19T20:13:46.962870Z","iopub.status.idle":"2023-05-19T20:13:50.081875Z","shell.execute_reply.started":"2023-05-19T20:13:46.962841Z","shell.execute_reply":"2023-05-19T20:13:50.080918Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"train_model(train_loader, model, EPOCHS, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:13:52.069401Z","iopub.execute_input":"2023-05-19T20:13:52.069826Z","iopub.status.idle":"2023-05-19T20:38:30.836327Z","shell.execute_reply.started":"2023-05-19T20:13:52.069791Z","shell.execute_reply":"2023-05-19T20:38:30.835357Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"100%|██████████| 14/14 [02:10<00:00,  9.31s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.03142813220620155\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.01s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6770833333333334 \t F1 Score: 0.617283950617284 \t Precision: 0.7936507936507936 \t Recall: 0.5050505050505051\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:59<00:00,  8.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.025761017575860023\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.29s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.828125 \t F1 Score: 0.8253968253968254 \t Precision: 0.8666666666666667 \t Recall: 0.7878787878787878\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:59<00:00,  8.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.026932379230856895\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:28<00:00,  9.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.828125 \t F1 Score: 0.8374384236453203 \t Precision: 0.8173076923076923 \t Recall: 0.8585858585858586\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:59<00:00,  8.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.02592451125383377\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8229166666666666 \t F1 Score: 0.8365384615384616 \t Precision: 0.7981651376146789 \t Recall: 0.8787878787878788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:58<00:00,  8.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.027630368247628212\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.828125 \t F1 Score: 0.8405797101449276 \t Precision: 0.8055555555555556 \t Recall: 0.8787878787878788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:58<00:00,  8.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 0.026038099080324173\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.30s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8229166666666666 \t F1 Score: 0.8365384615384616 \t Precision: 0.7981651376146789 \t Recall: 0.8787878787878788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:57<00:00,  8.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 0.025504382327198982\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8229166666666666 \t F1 Score: 0.8365384615384616 \t Precision: 0.7981651376146789 \t Recall: 0.8787878787878788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:59<00:00,  8.52s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 0.025638079270720482\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.23s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8229166666666666 \t F1 Score: 0.8365384615384616 \t Precision: 0.7981651376146789 \t Recall: 0.8787878787878788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:59<00:00,  8.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 0.026577584445476532\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.21s/it]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8229166666666666 \t F1 Score: 0.8365384615384616 \t Precision: 0.7981651376146789 \t Recall: 0.8787878787878788\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [01:57<00:00,  8.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 0.026363389566540718\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.23s/it]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8229166666666666 \t F1 Score: 0.8365384615384616 \t Precision: 0.7981651376146789 \t Recall: 0.8787878787878788\nFinished Training\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EVALUATION\nEvaluates on the validation data and produces metrics and confusion matrix","metadata":{}},{"cell_type":"code","source":"# Make evaluation on validation set\npredicted_labels, true_labels = make_preds(val_loader, model)\n\naccuracy = accuracy_score(true_labels, np.array(predicted_labels) > 0.5)\nf1 = f1_score(true_labels, np.array(predicted_labels) > 0.5)\nprecision = precision_score(true_labels, np.array(predicted_labels) > 0.5)\nrecall = recall_score(true_labels, np.array(predicted_labels) > 0.5)\n\nprint(f'Accuracy: {accuracy} \\t F1 Score: {f1} \\t Precision: {precision} \\t Recall: {recall}')\n\n# Confusion Matrix\nimport matplotlib.pyplot as plt\ncm = confusion_matrix(true_labels, np.array(predicted_labels) > 0.5)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T20:38:30.838595Z","iopub.execute_input":"2023-05-19T20:38:30.839299Z","iopub.status.idle":"2023-05-19T20:38:58.774740Z","shell.execute_reply.started":"2023-05-19T20:38:30.839262Z","shell.execute_reply":"2023-05-19T20:38:58.773827Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"100%|██████████| 3/3 [00:27<00:00,  9.21s/it]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6770833333333334 \t F1 Score: 0.617283950617284 \t Precision: 0.7936507936507936 \t Recall: 0.5050505050505051\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ac7490341f0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluate on test set\nEvaluates on the test dataloader and makes a submission.csv file","metadata":{}},{"cell_type":"code","source":"# make submission csv\nmodel = model.to(device)\npreds, filenames = make_preds_test(test_loader, model)\npreds = map(lambda x: x[0], preds)\nsubmission_df = pd.DataFrame(zip(filenames, preds), columns=['image_name', 'target'])\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization\nVisualization was done using the code provided by R. Vaishnav available at https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch-12a48cd1e573\n\nI have chosen not to include it here as it is not my own code, it was only modified slightly to pass the correct model to the code.","metadata":{}}]}